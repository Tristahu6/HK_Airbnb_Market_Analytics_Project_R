
**Step II: Prediction**

library(tidyverse)
library(forecast)

hk1 <- read.csv("hong_kong_cleaned.csv", header = TRUE)

*Step 1: Data exploration and partitioning*
### Removing outliers - we remove some outliers using the 99% quantile

library(tidyverse)
hk <- filter(hk1, hk1$price < quantile(hk1$price, 0.99))
hk <- filter(hk, hk$minimum_nights < quantile(hk1$minimum_nights, 0.99))
hk <- filter(hk, hk$beds < quantile(hk1$beds, 0.99))
hk <- filter(hk, hk$number_of_reviews < quantile(hk1$number_of_reviews, 0.99))
hk <- filter(hk, hk$host_listings_count < quantile(hk1$host_listings_count, 0.99))
hk <- filter(hk, hk$reviews_per_month < quantile(hk1$reviews_per_month, 0.99))

### Adjusting some variables - "bathroom_type" and "room_type" variable:
hk <- hk %>%
  mutate(
    bathroom_type = ifelse(bathroom_type == "half-bath", "shared", bathroom_type),
    room_type = ifelse(room_type == "Hotel room", "Private room", room_type)
  )

# partition the data
set.seed(699)
train.index <- sample(c(1:nrow(hk)), nrow(hk)*0.6)
train.df <- hk[train.index, ]
valid.df <- hk[-train.index, ]

#Variable selection
##distinguish between numeric and categorical variables since they will not receive the exact same treatement.
*Categorical variables:*
categ_var <-  c("description","X","neighborhood_overview", "host_id", "host_since","host_location", "host_response_time","host_is_superhost","host_neighbourhood","host_verifications","host_has_profile_pic", "host_identity_verified", "property_type",
              "room_type", "bathroom_type", "amenities", "amenities_categ","has_availability",
              "instant_bookable","got_reviewed")
##remove categorical variable with entirely unique values or redundant arbitrary values.
train.df <- train.df %>% select(-X,-host_id)
valid.df <- valid.df %>% select(-X,-host_id)

*remove redundant, overly specific and irrelevant categorical variables

categ_var2 <-  c("host_response_time","host_is_superhost","host_has_profile_pic", "host_identity_verified",
              "room_type", "bathroom_type", "has_availability",
              "instant_bookable","got_reviewed")

*"neighborhood_overview"*: most rentals don't have an overview. Moreover, by nature, it seems unique to a listing (higher counts than one might correspond to listings from the same host maybe). 
It is impossible to generalize since it is ultra specific textual data, that contains information that can be provided by other variables (e.g.: room type) and contains unnecessary details details on the Wai Chai neighborhood which is our only focus here anyways. 
It  could not work in our MLR model so we will remove them.

* *"description"*: similar situation.
* *"host_verifications"*:  does not seem to add much  (level of detail seems unnecessarily specfic -> every host provides different means of contact that do not seem meaningful in the context of our model to predict pricing

The different verification types (email, phone, work email) don't have an obvious direct relationship with price. In fact, it could be prone to overfitting by the model since the relationship is vague.It would also unnecessary noise and collinearity and would be redundant since other indicators of host reputation are kept.


* Remove *"host_has_profile_pic"* -> Very few "No" with higher prices (see box plotthe count below show that this variable scam?

******************

* Remove *"property_type"* and keep *"room_type"*
hk %>%
  group_by(hk$property_type) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

unique(train.df$property_type)

It has too many categories and room type keeps the main information from property type.

Therefore, we consider this information loss negligible compared to the issues the variable could cause, and *"room_type"* actually looks like it contains the appropriate amount of information without needing to bin it further.

* Keep *"bathroom_type" - It is relevant to the model and we expect it to have a relationship with price, which is why we decide to keep it.

* Keep *"has_availability"*

train.df %>%
  group_by(train.df$has_availability) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

* Keep *"instant_bookable"*

train.df %>%
  group_by(train.df$instant_bookable) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

* Keep *"got_reviewed"*

train.df %>%
  group_by(train.df$got_reviewed) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

* Remove *"host_location"* and *"host_neighborhood"* - The model is only meant to focus on Hong Kong listings, so the location of the host is not very relevant

For *"host_location"*, the majority is Hong Kong, with some very few specific abroad locations. Even if we binned it into two outcome classes "Hong Kong" and "abroad", there would still be a big risk of overfitting since the model would likely not be able to detect pattern to generalize with the limited information available in the "abroad" class. To avoid any risk for a variable that logically does not seem to closely correlate to pricing, we also will remove it. 

* Remove *"got_reviewed"*: this variable is likely to be highly correlated with the numeric review scores variables, that account in most cases for no review by assigning a 0 rating, and all other ratings correspond to a rating as shown below while giving more useful detail on the perceived value of the listing based on the customer satisfaction. Removing this binary classification, as it loses nuance/information on the demand/popularity, but this information is already available in the *"availability_ "* variables.

ggplot(train.df, aes(x=got_reviewed, y=review_scores_rating)) + geom_point() + geom_smooth(method="lm", se=FALSE, color="green")

* Remove *"amenities": unstructured text data that can't be digested in the prediction model 

#Handling numeric variables
num_var <- c("host_response_rate", "host_acceptance_rate","host_listings_count",
             "host_total_listings_count",
"latitude", "longitude", "accommodates", "bathroom_nb", "bedrooms", "beds",
"minimum_nights", "maximum_nights", "availability_30", "availability_60", "availability_90",
"availability_365", "number_of_reviews", "number_of_reviews_ltm", "number_of_reviews_l30d",
"review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness",
"review_scores_checkin", "review_scores_communication", "review_scores_location",
"review_scores_value", "calculated_host_listings_count_entire_homes",
"calculated_host_listings_count_private_rooms", "calculated_host_listings_count_shared_rooms",
"reviews_per_month")

*Eliminate multicolinearity - Remove highly correlated numeric variables*
cm<- cor(hk[num_var])

inds <- which(cm >= 0.65 & cm < 1, arr.ind = TRUE) #0.65 as selected treshold since there are a lot of variables
vars <- rownames(cm)

# Create dataframe with pairs respecting the correlation constraint
pairs <- data.frame(var1 = vars[inds[,1]],
                    var2 = vars[inds[,2]],
                    corr = cm[inds])

# Remove duplicate rows 
pairs <- pairs[!duplicated(t(apply(pairs, 1, sort))),]
print(pairs[order(-pairs$corr),])

Unsurprisingly, a lot of variables are redundant and we think it is likely to assume they would cause multicolinearity issues.

* Remove all *"review_scores"* variables
"review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", "review_scores_location" and "review_scores_value"

Based on Aribnb ratings, similar to Uber -> 5 stars are very frequent, and a lot of customers rate five stars for all categories when they are satisfied.
the categorical variable "*got_reviewed*" is more relevant here, as explained further below.                             

* Similarly, remove all *"number_of_reviews_"* variables

Similarly and additionally for *"number_of_reviews", "number_of_reviews_ltm" and "number_of_reviews_l30d"*, which have relatively high correlation coefficients with the *"review_score_"* variables. 

We can argue that is is also redundant in the sense that it's another indicator of occupancy/demand signals like the *"availaility_"* variables.



* *"availability_30", "availability_60", "availability_90" and "availability_365"*: we will only keep *"availability_365"*


* Only keep *"host_listings_count"*

Among *host_listings_count,host_total_listings_count,calculated_host_listings_count_entire_homes,calculated_host_listings_count_shared_rooms and calculated_host_listings_count_private_rooms*


We will only keep the variable *"host_listings_count"*, since it provides an overall grouping and the detailed subdivision counts (variables starting by "calculated_host_listings_count_") doesn't seem relevant for our model.

* Keep *"accomodates"* and *"bedrooms"*, remove *"beds"*

Since "beds" and "bedrooms" have a high correlation coefficient according to the correlation table, and bedrooms has a lower correlation with accomodates (which doesn't have a high correlation with any other variable), we decided to only remove the most correlated variable: "beds" to avoid multicolinearity.




*Logarithmic transformation of the response variable price*

Since we have identified in the data cleaning step that the price variable had a significant number of outliers, let's also try creating a model using log(price) to see if it helps mitigate the impact of these extreme outliers that can skew the results of our model. 
The logarithmic transformation should be able to shrink the effect of extreme values, making the regression model more robust.

```{r}
train.df$log_price = log(train.df$price)
valid.df$log_price = log(valid.df$price)
```

This will also be needed for visualization purposes since otherwise, the distribution is unreadable since the plots appear completely "skewed" or "squeezed" towards the bottom due to the presence of outliers in the price data. 

*Remove variables with less significant predictive power in relation to the variable price*


*Visualizations to further assess relevancy*

To further assess relevancy, we will make visualizations for both categorical and numeric variables not excluded from the model yet and look into their relationship with the price variable.


*Categorical variables*


* Remove *"host_since"*

*"host_since"* has a unique specific date value for each host, which would not be viable in the model by itself. 
We considered converting it to proper dates format and only extracting the year, however, we assume that the host experience in terms of years, which most likely correspond to the date of registration as an Airbnb host, is less relevant than the Superhost status for example when accounting for the experience, recognition and reputation of a host.
This is why to avoid a clear risk of overfitting and to avoid adding a less relevant variable that does not show a clear relationship with price, we chose to remove host_since. When we look at the box plots, it seems that even collapsing the levels or grouping them would not be relevant as a predictor for price.

```{r}
library(lubridate)
```

```{r}
train.df$host_since_y<-ymd(train.df$host_since)
```

```{r}
train.df <- train.df %>%
  mutate(host_since_y = factor(year(host_since)))
```

```{r}
ggplot(train.df, aes(x = host_since_y, y = log_price)) +
  geom_boxplot()
```


```{r}
train.df <- train.df %>% select(-host_since_y)
```

```{r}
ggplot(train.df, aes(x = host_is_superhost, y = log_price)) +
  geom_boxplot()
```

```{r}
ggplot(train.df, aes(x = host_identity_verified, y = log_price)) +
  geom_boxplot()
```

```{r}
ggplot(train.df, aes(x = room_type, y = log_price)) +
  geom_boxplot()
```

We can clearly see the price is influenced by those categories.
We should keep them, we will try a model that can remove the unnecessary ones later




*Numeric variables*


```{r}
ggplot(train.df, aes(x=host_listings_count, y=log_price)) + geom_point() + geom_smooth(method="lm", se=FALSE, color="green")
```

```{r}
ggplot(train.df, aes(x=latitude, y=log_price)) + geom_point() + geom_smooth(method="lm", se=FALSE, color="green")
```

```{r}
ggplot(train.df, aes(x=accommodates, y=log_price)) + geom_point() + geom_smooth(method="lm", se=FALSE, color="green")
```


*Step 3: Data preparation*
              

              
```{r}
sapply(train.df[categ_var2], is.factor)
```

```{r}
train.df[categ_var] <- lapply(train.df[categ_var2], as.factor)
valid.df[categ_var] <- lapply(valid.df[categ_var2], as.factor)
```

```{r}
sapply(train.df[categ_var2], is.factor)
```

Let's now clean up our training and validation sets, by removing the eliminated variables from this step, additionally to "X" and "host_id".

```{r}
train.df <- train.df %>% select( -description,-neighborhood_overview,-host_since,-host_neighbourhood,
                                 -host_location,-property_type,-amenities,-host_total_listings_count,
                                 -host_verifications,-availability_30,-availability_60,-availability_90,
                                 -number_of_reviews,-number_of_reviews_ltm,-number_of_reviews_l30d,
                                 -review_scores_rating,-review_scores_accuracy,
                                 -review_scores_cleanliness,-review_scores_checkin,
                                 -review_scores_communication,-review_scores_location,
                                 -review_scores_value,-calculated_host_listings_count_entire_homes,
                                 -calculated_host_listings_count_private_rooms,
                                 -calculated_host_listings_count_shared_rooms,-reviews_per_month,-beds, -X,
                                 -log_price, -host_id, -amenities_categ)
```

```{r}
valid.df <- valid.df %>% select( -description,-neighborhood_overview,-host_since,-host_neighbourhood,
                                 -host_location,-property_type,-amenities,-host_total_listings_count,
                                 -host_verifications,-availability_30,-availability_60,-availability_90,
                                 -number_of_reviews,-number_of_reviews_ltm,-number_of_reviews_l30d,
                                 -review_scores_rating,-review_scores_accuracy,
                                 -review_scores_cleanliness,-review_scores_checkin,
                                 -review_scores_communication,-review_scores_location,
                                 -review_scores_value,-calculated_host_listings_count_entire_homes,
                                 -calculated_host_listings_count_private_rooms,
                                 -calculated_host_listings_count_shared_rooms,-reviews_per_month,-beds, -X,
                                 -log_price, -host_id, -amenities_categ)
```



*Step 4: Model building*


*MLR Model with price as a response variable*

Using backward elimination, build the mutliple linear regression model with the data in our training set, to predict the price variable.

```{r}
library(stats)
```

### B

```{r}
mlr_model<-lm(price ~ ., data = train.df)
mlr_model.step <- step(mlr_model, direction = "backward")
```

*Summary of the MLR model with price*

```{r}
summary(mlr_model.step)
```

Now let us try with log it could improve the model we've seen previously that
on visualizations the relationship is more linear with log price.


*MLR Model with log(price) as a response variable*

```{r}
log_mlr_model<-lm(log(price) ~ ., data = train.df)
log_mlr_model.step <- step(log_mlr_model, direction = "backward")
summary(log_mlr_model.step)
```

The model with log price has higher adjusted r-squared so we keep this last one.

Its coefficients are written in the estimates. The equation is the following:

Ŷ= a+ b1 x X1 + b2 x X2 +...+ bp x Xp

where Ŷ is the prediction, a is the intercept and b1 to bp are the coefficients in the estimate and X1 to Xp are the inputs of the predictors.


### C. Analysis of other model metrics

After the using the log price instead of price and backwards elimination our adjusted R squared improved by over 0.2 it is now 0.78.

This could be explained by the fact that the distribution of the price is very skewed which would not be surprising because we have many outliers as seen previously.
It could also be explained by the fact that the price became more linear after the log transformation.

Let us test the model with the validation set now to evaluate its performance.
We have to transform the price of the validation to log first.

```{r}
valid.df$price <- sapply(valid.df$price, log)
library(rsq)
library(Metrics)
predicted_values <- predict(log_mlr_model.step, newdata = valid.df)
sse <- sum((valid.df$price - predicted_values)^2)
sst <- sum((valid.df$price - mean(valid.df$price))^2)
r_sq <- 1 - (sse/sst)
r_sq
```

We get a R_squared of 0.74 which is close to the traning data set. 
This means the model is not overfitted.
Finally let us look at the RMSE and min and max residuals. We have to bring back the values without the log transformation to be able to interprete it.

```{r}
valid.df$price <- sapply(valid.df$price,exp)
predicted_values <- sapply(predicted_values,exp)
  
RMSE <- rmse(valid.df$price, predicted_values)
Min_Residual <- min(valid.df$price-predicted_values)
Max_Residual <- max(valid.df$price-predicted_values)

RMSE
Min_Residual
Max_Residual
```

The RMSE is of 388, on average the models makes a mistake of 388 which is consiquent considering that most apartments have a price around 600.

The minimum residual is around -2000 and maximum residual 2000 this represents the highest mistake the model can make. 

Based on those performance metrics we can conclude that the model is fair at predicting price but it still makes mistakes by a margin.
